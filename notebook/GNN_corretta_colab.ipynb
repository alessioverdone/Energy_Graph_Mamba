{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK7eeSOkwoy-"
      },
      "source": [
        "# **Start**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMcCRnfAwZCA"
      },
      "outputs": [],
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2VLoyMmwnfZ"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install -qqq wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "metadata": {
        "id": "tcsVDPf3q6Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4ehKnIwwvfa"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "\n",
        "Substitute this two lines in dataloader.py ad delete the 2 corrispective imports of torch._six\n",
        "\n",
        "import collections.abc as container_abcs\n",
        "int_classes = int \n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import collections.abc as container_abcs\n",
        "from torch.nn import functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torch_geometric_temporal.nn.recurrent import GConvLSTM\n"
      ],
      "metadata": {
        "id": "URiiJ0CBpyJW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IOPhZ-_TwxET"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "\n",
        "\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import numpy as np\n",
        "from time import strftime\n",
        "import torch.nn as nn\n",
        "import io\n",
        "import json\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zriOGFCXw6pi",
        "outputId": "a904ffd1-5ea1-426e-d7da-c7e4abfebf51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5upoW4jw0Xu"
      },
      "source": [
        "# **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PlFWOs_hw82U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import wandb\n",
        "import io\n",
        "import PIL\n",
        "import torch.autograd as autograd\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "from pylab import rcParams\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from palettable.cartocolors.sequential import SunsetDark_6\n",
        "\n",
        "\n",
        "def getVariablesClass(inst):\n",
        "    var = []\n",
        "    cls = inst.__class__\n",
        "    for v in cls.__dict__:\n",
        "        if not callable(getattr(cls, v)):\n",
        "            var.append(v)\n",
        "    return var\n",
        "\n",
        "\n",
        "def get_hyperparams_dict(p):\n",
        "    params_list = getVariablesClass(p)\n",
        "    d = dict()\n",
        "    for pos, var in enumerate(params_list):\n",
        "        d[var] = getattr(p, var)\n",
        "    return d\n",
        "\n",
        "\n",
        "def degrade_dataset(X, missingness, rand, v):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        X : dataset to corrupt\n",
        "        missingness : % of data to eliminate[0,1]\n",
        "        rand : random state\n",
        "        v : replace with = 'zero' or 'nan'\n",
        "      Outputs:\n",
        "        corrupted Dataset\n",
        "        binary mask\n",
        "    \"\"\"\n",
        "    x_temp = X.clone()\n",
        "    X_1d = x_temp.flatten()  # X.shape = #lags x #station\n",
        "    n = len(X_1d)\n",
        "    # mask_1d = torch.ones(n)\n",
        "    mask_1d = torch.zeros(n)\n",
        "\n",
        "    corrupt_ids = random.sample(range(n), int(missingness * n))\n",
        "    for i in corrupt_ids:\n",
        "        X_1d[i] = v\n",
        "        # mask_1d[i] = 0\n",
        "        mask_1d[i] = 1\n",
        "\n",
        "    cX = X_1d.reshape(X.shape)\n",
        "    mask = mask_1d.reshape(X.shape)\n",
        "    mask = mask.byte()\n",
        "\n",
        "    return cX, mask\n",
        "\n",
        "\n",
        "def check_mask(x, device, v=-1):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        x : data batch corrupted\n",
        "    Outputs:\n",
        "        mask : 1=corrupted, 0=original # nel paper fa l'opposto\n",
        "    \"\"\"\n",
        "    x.to(device)\n",
        "    if x.dim() == 1:\n",
        "        dim_x = x.shape[0]\n",
        "    else:\n",
        "        dim_x = x.shape[1]\n",
        "    ones = torch.ones(dim_x).to(device)\n",
        "    zeros = torch.zeros(dim_x).to(device)\n",
        "    mask = torch.where(x != v, zeros, ones)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_only_day_data(y, h, device):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        y : data to rpedict\n",
        "    Outputs:\n",
        "        night_mask : 1=day, 0=night\n",
        "    \"\"\"\n",
        "    y.to(device)\n",
        "    h.to(device)\n",
        "    dim_y = y.shape\n",
        "    ones = torch.ones(dim_y).to(device)\n",
        "    zeros = torch.zeros(dim_y).to(device)\n",
        "    mask = torch.where(y == 0.0, zeros, ones)\n",
        "    h = mask * h\n",
        "\n",
        "    return h\n",
        "\n",
        "\n",
        "def buffer_plot_and_get(fig):\n",
        "    \"\"\"\n",
        "    Util function for visualization output\n",
        "    \"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf)\n",
        "    buf.seek(0)\n",
        "    return PIL.Image.open(buf)\n",
        "\n",
        "\n",
        "def visualization_output_imputation(features, targets, predictions, predictions_rec, params, station_name):\n",
        "    \"\"\"\n",
        "    Create images from features, preditions and targets data for data imputation task\n",
        "    \"\"\"\n",
        "    x_axis_feature = np.arange(params.LAGS)\n",
        "    fig, ax = plt.subplots(figsize=(15, 15))\n",
        "    ax.plot(x_axis_feature, features.cpu(), \"-g\", label=\"features_\" + station_name)\n",
        "    ax.plot(x_axis_feature, targets.cpu(), \"-b\", label=\"target_\" + station_name)\n",
        "    ax.plot(x_axis_feature, predictions_rec.cpu(), \"-r\", label=\"predicted_rec_\" + station_name)\n",
        "    ax.plot(x_axis_feature, predictions.cpu(), \"-y\", label=\"predicted_\" + station_name)\n",
        "    plt.title(station_name)\n",
        "    pil_image = buffer_plot_and_get(fig)\n",
        "    return pil_image, plt\n",
        "\n",
        "\n",
        "def visualization_output_imputation_F(x, y_f, h_f, params, station_name):\n",
        "    \"\"\"\n",
        "    Create images from features, preditions and targets data for data imputation task\n",
        "    \"\"\"\n",
        "    x_axis_feature = np.arange(params.LAGS)\n",
        "    x_axis_target = np.arange(params.LAGS - 1, params.LAGS + params.PREDICTION_WINDOW)\n",
        "    target_sequence = torch.cat((x[-1].unsqueeze(dim=0).cpu(), y_f.cpu()))\n",
        "    predicted_sequence = torch.cat((x[-1].unsqueeze(dim=0).cpu(), h_f.cpu()))\n",
        "    fig, ax = plt.subplots(figsize=(25, 15))\n",
        "\n",
        "    ax.plot(x_axis_feature, x.cpu(), linestyle='-', color='b', label=\"y_i_\" + station_name)\n",
        "    ax.plot(x_axis_target, target_sequence.cpu(), linestyle='--', color=\"b\", label=\"y_f_\" + station_name)\n",
        "    ax.plot(x_axis_target, predicted_sequence.cpu(), linestyle='-', color=\"r\", label=\"h_f_\" + station_name)\n",
        "    ax.plot([x_axis_feature[-1], x_axis_feature[-1]], [-0.2, 1], linestyle='-.', color='k',\n",
        "            label=\"limit_\" + station_name)\n",
        "\n",
        "    plt.title(station_name)\n",
        "    plt.xlabel(\"Hours\")\n",
        "    # plt.ylabel(\"Output\")\n",
        "    pil_image = buffer_plot_and_get(fig)\n",
        "\n",
        "    return pil_image, plt\n",
        "\n",
        "\n",
        "def visualization_output_imputation_IF(x_c, y_i, h_i, h_i_rec, y_f, h_f, params, station_name):\n",
        "    \"\"\"\n",
        "    Create images from features, preditions and targets data for data imputation task\n",
        "    \"\"\"\n",
        "    x_axis_feature = np.arange(params.LAGS)\n",
        "    x_axis_target = np.arange(params.LAGS - 1, params.LAGS + params.PREDICTION_WINDOW)\n",
        "    target_sequence = torch.cat((y_i[-1].unsqueeze(dim=0).cpu(), y_f.cpu()))\n",
        "    predicted_sequence = torch.cat((y_i[-1].unsqueeze(dim=0).cpu(), h_f.cpu()))\n",
        "    h_i = torch.cat((h_i.cpu(), y_f[0].unsqueeze(dim=0).cpu()))\n",
        "    # plt.stem(x_axis_feature, np.array(x_c))\n",
        "    fig, ax = plt.subplots(figsize=(25, 15))\n",
        "\n",
        "    # Combination of style #1\n",
        "\n",
        "    # ax.plot(x_axis_feature, x_c.cpu(), 'o-', color='g',  label=\"x_c_\" + station_name) #'o-',\n",
        "    # ax.plot(x_axis_feature, y_i.cpu(), 'o-', color='b', label=\"y_i_\" + station_name)\n",
        "    # ax.plot(x_axis_feature_1, h_i.cpu(), 'o-', color=\"y\", label=\"h_i_\" + station_name)\n",
        "    # ax.plot(x_axis_target, target_sequence.cpu(), 'o-', color=\"b\", label=\"y_f_\" + station_name)\n",
        "    # ax.plot(x_axis_target, predicted_sequence.cpu(), 'o-', color=\"r\", label=\"h_f_\" + station_name)\n",
        "    # ax.plot(x_axis_feature, h_i_rec.cpu(), 'o-', color=\"r\", label=\"h_i_rec_\" + station_name)\n",
        "\n",
        "    # Combination of style #2\n",
        "    # ax.plot(x_axis_feature, x_c.cpu(), linestyle='--', color='g',  label=\"x_c_\" + station_name) #'o-', 'r*'\n",
        "    mask = check_mask(x_c.cpu(), 'cpu').byte()\n",
        "    x_axis_feature_tensor = torch.tensor(x_axis_feature)\n",
        "    x_axis_corrupted = x_axis_feature_tensor[mask]\n",
        "    ax.plot(x_axis_feature, y_i.cpu(), linestyle='--', color='b', label=\"y_i_\" + station_name)\n",
        "    # ax.plot(x_axis_feature_1, h_i.cpu(), linestyle='-.', color=\"y\", label=\"h_i_\" + station_name) # all x predicted\n",
        "    ax.plot(x_axis_target, target_sequence.cpu(), linestyle='--', color=\"b\", label=\"y_f_\" + station_name)\n",
        "    ax.plot(x_axis_target, predicted_sequence.cpu(), linestyle='-', color=\"r\", label=\"h_f_\" + station_name)\n",
        "    ax.plot(x_axis_feature, h_i_rec.cpu(), linestyle='-', color=\"r\", label=\"h_i_rec_\" + station_name)\n",
        "    ax.plot(x_axis_corrupted, np.ones(len(x_axis_corrupted)) * -0.001, 'kP', label=\"x_c_\" + station_name)  # 'o-',\n",
        "    ax.plot([x_axis_feature[-1], x_axis_feature[-1]], [-0.2, 1], linestyle='-.', color='k',\n",
        "            label=\"limit_\" + station_name)\n",
        "\n",
        "    plt.title(station_name)\n",
        "    plt.xlabel(\"Hours\")\n",
        "    # plt.ylabel(\"Output\")\n",
        "    pil_image = buffer_plot_and_get(fig)\n",
        "    return pil_image, plt\n",
        "\n",
        "\n",
        "def load_prediction_data(x, h, y, params, mask, phase):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        x : data batch corrupted\n",
        "        h : predictions\n",
        "        y : targets\n",
        "    Outputs:\n",
        "        Load images on wandb logger\n",
        "    \"\"\"\n",
        "\n",
        "    index = random.randint(0, params.NUM_STATION - 1)\n",
        "    mask = (mask[index, :]).float()\n",
        "    features = x[index, :]\n",
        "    predictions = h[index, :]\n",
        "    targets = y[index, :]\n",
        "    predictions_reconstructed = torch.mul(mask, predictions) + torch.mul(1 - mask, features)\n",
        "    image_plot, plt_plot = visualization_output_imputation(features, targets, predictions, predictions_reconstructed,\n",
        "                                                           params,\n",
        "                                                           station_name=str(index))\n",
        "    wandb.log({phase + \"_plot\": plt_plot})\n",
        "    wandb.log({phase + \"_images\": wandb.Image(image_plot)})\n",
        "\n",
        "\n",
        "def load_prediction_data_IF(x_c, h_i, y_i, y_f, h_f, params, mask, phase):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        x : data batch corrupted\n",
        "        h : predictions\n",
        "        y : targets\n",
        "    Outputs:\n",
        "        Load images on wandb logger\n",
        "    \"\"\"\n",
        "\n",
        "    index = random.randint(0, params.NUM_STATION - 1)\n",
        "    mask = (mask[index, :]).float()\n",
        "    features_corrupted = x_c[index, :]\n",
        "    predictions_i = h_i[index, :]\n",
        "    targets_i = y_i[index, :]\n",
        "    predictions_f = h_f[index, :]\n",
        "    targets_f = y_f[index, :]\n",
        "    predictions_reconstructed_i = torch.mul(mask, predictions_i) + torch.mul(1 - mask, targets_i)\n",
        "    image_plot, plt_plot = visualization_output_imputation_IF(features_corrupted, targets_i, predictions_i,\n",
        "                                                              predictions_reconstructed_i,\n",
        "                                                              targets_f,\n",
        "                                                              predictions_f,\n",
        "                                                              params,\n",
        "                                                              station_name=str(index))\n",
        "    wandb.log({phase + \"_plot\": plt_plot})\n",
        "    wandb.log({phase + \"_images\": wandb.Image(image_plot)})\n",
        "\n",
        "\n",
        "def load_prediction_data_F(x, y_f, h_f, params, phase):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        x : data batch corrupted\n",
        "        h : predictions\n",
        "        y : targets\n",
        "    Outputs:\n",
        "        Load images on wandb logger\n",
        "    \"\"\"\n",
        "\n",
        "    index = random.randint(0, params.NUM_STATION - 1)\n",
        "    features_f = x[index, :]\n",
        "    predictions_f = h_f[index, :]\n",
        "    targets_f = y_f[index, :]\n",
        "    image_plot, plt_plot = visualization_output_imputation_F(features_f,\n",
        "                                                             targets_f,\n",
        "                                                             predictions_f,\n",
        "                                                             params,\n",
        "                                                             station_name=str(index))\n",
        "    wandb.log({phase + \"_plot\": plt_plot})\n",
        "    wandb.log({phase + \"_images\": wandb.Image(image_plot)})\n",
        "\n",
        "\n",
        "def load_prediction_data_F2(x, y_f, h_f, params, phase):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        x : data batch corrupted\n",
        "        h : predictions\n",
        "        y : targets\n",
        "    Outputs:\n",
        "        Load images on wandb logger\n",
        "    \"\"\"\n",
        "\n",
        "    index = random.randint(0, params.NUM_STATION - 1)\n",
        "    features_f = x[index, :]\n",
        "    predictions_f = h_f[index, :]\n",
        "    targets_f = y_f[index, :]\n",
        "    image_plot, plt_plot = visualization_output_imputation_F2(features_f,\n",
        "                                                              targets_f,\n",
        "                                                              predictions_f,\n",
        "                                                              params,\n",
        "                                                              station_name=str(index))\n",
        "    # wandb.log({phase + \"_plot\": plt_plot})\n",
        "    wandb.log({phase + \"_images\": wandb.Image(image_plot)})\n",
        "\n",
        "\n",
        "def visualization_output_imputation_F2(x, y_f, h_f, params, station_name):\n",
        "    \"\"\"\n",
        "    Create images from features, preditions and targets data for data imputation task\n",
        "    \"\"\"\n",
        "\n",
        "    params_img = {\n",
        "        'axes.labelsize': 10,\n",
        "        'font.family': 'Times New Roman',\n",
        "        'font.size': 11,\n",
        "        'legend.fontsize': 9,\n",
        "        'xtick.labelsize': 9,\n",
        "        'ytick.labelsize': 9,\n",
        "        'text.usetex': False,\n",
        "        'figure.figsize': [4.7, 3.2],\n",
        "        'lines.linewidth': 1.2\n",
        "    }\n",
        "\n",
        "    rcParams.update(params_img)\n",
        "    matplotlib.rc('pdf', fonttype=42)\n",
        "    # matplotlib.font_manager._rebuild()\n",
        "\n",
        "    x_axis_feature = np.arange(params.LAGS)\n",
        "    x_axis_target = np.arange(params.LAGS - 1, params.LAGS + params.PREDICTION_WINDOW)\n",
        "    target_sequence = torch.cat((x[-1].unsqueeze(dim=0).cpu(), y_f.cpu()))\n",
        "    predicted_sequence = torch.cat((x[-1].unsqueeze(dim=0).cpu(), h_f.cpu()))\n",
        "\n",
        "    colors = SunsetDark_6.mpl_colors\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.yaxis.grid(linewidth=0.5, alpha=0.3)\n",
        "\n",
        "    # plt.plot(np.ones(10), color=colors[0], label='Prova')\n",
        "    plt.plot(x_axis_feature, x.cpu(), linestyle='-', color='b', label=\"S_x\")  # Input sequence\"\n",
        "    plt.plot(x_axis_target, target_sequence.cpu(), linestyle='--', color=\"b\", label=\"S_y\")  # Target sequence\n",
        "    plt.plot(x_axis_target, predicted_sequence.cpu(), linestyle='-', color=\"r\", label=\"S_h\")  # Predicted sequence\n",
        "    plt.plot([x_axis_feature[-1], x_axis_feature[-1]], [-0.2, 1], linestyle='-.',\n",
        "             color='k')  # , label=\"Current timestep\")\n",
        "\n",
        "    # plt.xlim(0, 9)\n",
        "    # plt.ylim(0, 2)\n",
        "    plt.xlabel('Hours')\n",
        "    plt.ylabel('Normalized power')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    # plt.show()\n",
        "    id = random.randint(1, 1000000)\n",
        "    if params.SAVE_IMGS:\n",
        "        fig.savefig('imgs/' + str(id) + '_prova.pdf', bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "    # fig, ax = plt.subplots(figsize=(25, 15))\n",
        "\n",
        "    # ax.plot(x_axis_feature, x.cpu(), linestyle='-', color='b', label=\"y_i_\" + station_name)\n",
        "    # ax.plot(x_axis_target, target_sequence.cpu(), linestyle='--', color=\"b\", label=\"y_f_\" + station_name)\n",
        "    # ax.plot(x_axis_target, predicted_sequence.cpu(), linestyle='-', color=\"r\", label=\"h_f_\" + station_name)\n",
        "    # ax.plot([x_axis_feature[-1], x_axis_feature[-1]], [-0.2, 1], linestyle='-.', color='k',\n",
        "    #         label=\"limit_\" + station_name)\n",
        "\n",
        "    plt.title(station_name)\n",
        "    # plt.xlabel(\"Hours\")\n",
        "    # plt.ylabel(\"Output\")\n",
        "    pil_image = buffer_plot_and_get(fig)\n",
        "\n",
        "    return pil_image, plt\n",
        "\n",
        "\n",
        "def hard_gradient_penalty(net, real_data, fake_data, device):\n",
        "    mask = torch.FloatTensor(real_data.shape).to(device).uniform_() > 0.5\n",
        "    inv_mask = ~mask\n",
        "    mask, inv_mask = mask.float(), inv_mask.float()\n",
        "\n",
        "    interpolates = mask * real_data + inv_mask * fake_data\n",
        "    interpolates = interpolates.to(device)\n",
        "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
        "    c_interpolates = net(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(\n",
        "        outputs=c_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=torch.ones(c_interpolates.size()).to(device),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gp = (gradients.norm(2, dim=1) - 1).pow(2).mean()\n",
        "    return gp\n",
        "\n",
        "\n",
        "# Cumulative loss display\n",
        "def loss_used(params):\n",
        "    loss_list = []\n",
        "\n",
        "    # if params.IMPUTATION:\n",
        "    #     loss_list.append('test_loss_imputation')\n",
        "    #     loss_list.append('test_MAE_imputation')\n",
        "    #     if params.FORECASTING:\n",
        "    #         if params.MULTIVARIATE:\n",
        "    #             loss_list.append('test_loss_IFM_power')\n",
        "    #             loss_list.append('test_loss_IFM_temp')\n",
        "    #             loss_list.append('test_loss_IFM_wind')\n",
        "    #             loss_list.append('test_MAE_IFM')\n",
        "    #         else:\n",
        "    #             loss_list.append('test_loss_IFU')\n",
        "    #             loss_list.append('test_MAE_IFU')\n",
        "    # else:\n",
        "    if params.FORECASTING:\n",
        "        if params.MULTIVARIATE:\n",
        "            loss_list.append('test_loss_FM_power')\n",
        "            loss_list.append('test_MAE_FM')\n",
        "            # loss_list.append('test_loss_FM_temp')\n",
        "            # loss_list.append('test_loss_FM_wind')\n",
        "        else:\n",
        "            loss_list.append('test_loss_FU')\n",
        "            loss_list.append('test_MAE_FU')\n",
        "\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "def get_value_of_same_loss(list_of_dict, name):\n",
        "    values = []\n",
        "    for d in list_of_dict:\n",
        "        values.append(d[name])\n",
        "    return np.array(values)\n",
        "\n",
        "\n",
        "def print_runs_results(params, RUNS, results):\n",
        "    loss_names = loss_used(params)\n",
        "    for name in loss_names:\n",
        "        loss_values = get_value_of_same_loss(results, name)\n",
        "        mean = loss_values.mean()\n",
        "        std = loss_values.std()\n",
        "        print(\"----\", name, \"----\")\n",
        "        print(\"Mean: \", mean, \"Std: \", std)\n",
        "        print(\"EXC_Mean: \", str(mean).replace('.', ','), \"EXC_Std: \", str(std).replace('.', ','), '\\n')\n",
        "        # print(loss_values)\n",
        "\n",
        "\n",
        "# Shuffle dataset\n",
        "def temporal_signal_split_and_shuffle(data_iterator, shuffle=True, train_ratio: float = 0.8):\n",
        "    if shuffle:\n",
        "        train_snapshots = int(train_ratio * data_iterator.snapshot_count)\n",
        "        total_lenght = data_iterator.snapshot_count\n",
        "        feature_index = np.arange(total_lenght, dtype=int)\n",
        "        np.random.shuffle(feature_index)\n",
        "        train_index = feature_index[0:train_snapshots].tolist()\n",
        "        test_index = feature_index[train_snapshots:].tolist()\n",
        "\n",
        "        if type(data_iterator) == StaticGraphTemporalSignal:\n",
        "            train_features = np.array(data_iterator.features)[train_index]\n",
        "            train_targets = np.array(data_iterator.targets)[train_index]\n",
        "            test_features = np.array(data_iterator.features)[test_index]\n",
        "            test_targets = np.array(data_iterator.targets)[test_index]\n",
        "            train_iterator = StaticGraphTemporalSignal(\n",
        "                data_iterator.edge_index,\n",
        "                data_iterator.edge_weight,\n",
        "                train_features,\n",
        "                train_targets,\n",
        "            )\n",
        "\n",
        "            test_iterator = StaticGraphTemporalSignal(\n",
        "                data_iterator.edge_index,\n",
        "                data_iterator.edge_weight,\n",
        "                test_features,\n",
        "                test_targets,\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        train_snapshots = int(train_ratio * data_iterator.snapshot_count)\n",
        "        if type(data_iterator) == StaticGraphTemporalSignal:\n",
        "            train_iterator = StaticGraphTemporalSignal(\n",
        "                data_iterator.edge_index,\n",
        "                data_iterator.edge_weight,\n",
        "                data_iterator.features[0:train_snapshots],\n",
        "                data_iterator.targets[0:train_snapshots],\n",
        "            )\n",
        "\n",
        "            test_iterator = StaticGraphTemporalSignal(\n",
        "                data_iterator.edge_index,\n",
        "                data_iterator.edge_weight,\n",
        "                data_iterator.features[train_snapshots:],\n",
        "                data_iterator.targets[train_snapshots:],\n",
        "            )\n",
        "\n",
        "    return train_iterator, test_iterator\n",
        "\n",
        "\n",
        "# Define run name\n",
        "def get_run_name(db, input_ws, output_ws, params):\n",
        "    # Test\n",
        "    test = '-'\n",
        "    if params.FORECASTING:\n",
        "        test = 'F'\n",
        "        if params.MULTIVARIATE:\n",
        "            test += 'M'\n",
        "\n",
        "    name_run = \"%s_%s_%s_%s_%s\" % (params.GNN_MODEL, test, db, input_ws, output_ws)\n",
        "    return name_run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4nS3mUgxMKP"
      },
      "source": [
        "# **Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LrSOOmhkxIm9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from torch_geometric_temporal.nn.recurrent import GConvLSTM\n",
        "\n",
        "\n",
        "class GNN_Forecasting(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Model for doing forecasting on temporal series data\n",
        "    Functions:\n",
        "        __init__\n",
        "        forward\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params):\n",
        "        super(GNN_Forecasting, self).__init__()\n",
        "        self.params = params\n",
        "        self.recurrent = GConvLSTM(self.params.INPUT_FEATURE_DIMENSION, self.params.FILTERS,\n",
        "                                   self.params.FILTER_SIZE)\n",
        "        self.recurrent2 = GConvLSTM(self.params.FILTERS, self.params.FILTERS,\n",
        "                                    self.params.FILTER_SIZE)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear = torch.nn.Linear(self.params.INPUT_MLP_DIMENSION, self.params.OUTPUT_MLP_DIMENSION_FORECASTING)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        h_0 = torch.zeros(x.shape[0], self.params.FILTERS).to(x.device)\n",
        "        c_0 = torch.zeros(x.shape[0], self.params.FILTERS).to(x.device)\n",
        "        h_1 = torch.zeros(x.shape[0], self.params.FILTERS).to(x.device)\n",
        "        c_1 = torch.zeros(x.shape[0], self.params.FILTERS).to(x.device)\n",
        "        x = torch.reshape(x, (-1, self.params.INPUT_FEATURE_DIMENSION, self.params.LAGS))\n",
        "        for i in range(self.params.LAGS):\n",
        "            x_t = x[:, :, i]\n",
        "            h_0, c_0 = self.recurrent(x_t, edge_index, edge_weight, H=h_0, C=c_0)\n",
        "            h_0 = self.relu(h_0)\n",
        "            h_1, c_1 = self.recurrent2(h_0, edge_index, edge_weight, H=h_1, C=c_1)\n",
        "            h_1 = self.tanh(h_1)\n",
        "        h = self.linear(h_1)\n",
        "        return h\n",
        "\n",
        "\n",
        "class LSTM_Forecasting(pl.LightningModule):\n",
        "    def __init__(self, params):\n",
        "        super(LSTM_Forecasting, self).__init__()\n",
        "        self.params = params\n",
        "\n",
        "        self.rnn = nn.LSTM(self.params.INPUT_FEATURE_DIMENSION,\n",
        "                           self.params.HIDDEN_DIMENSION_SINGLE,\n",
        "                           num_layers=self.params.NUMBER_LSTM_LAYERS,\n",
        "                           batch_first=True)\n",
        "\n",
        "        self.linear = torch.nn.Linear(self.params.HIDDEN_DIMENSION_SINGLE * self.params.LAGS,\n",
        "                                      self.params.OUTPUT_MLP_DIMENSION_FORECASTING)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.params.MULTIVARIATE:\n",
        "            x = torch.reshape(x, (x.size(0), 3, self.params.LAGS))  # batch, feat, seq\n",
        "        else:\n",
        "            x = torch.unsqueeze(x, dim =1)\n",
        "        x = torch.transpose(x, 1, 2)  # batch, seq, feat\n",
        "        h, _ = self.rnn(x)  # batch, seq, hid\n",
        "        h = h.reshape(h.size(0), -1)\n",
        "        h = self.linear(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class CNN_Forecasting(pl.LightningModule):\n",
        "    def __init__(self, params):\n",
        "        super(CNN_Forecasting, self).__init__()\n",
        "        self.params = params\n",
        "        # CONV1\n",
        "        kernel_size = 5\n",
        "        in_channels = self.params.INPUT_FEATURE_DIMENSION\n",
        "        out_channels = 8\n",
        "        in_features = 24\n",
        "        out_features = 20\n",
        "        padding = int((out_features - in_features + kernel_size - 1) / 2)\n",
        "        self.cnn1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "        self.relu = nn.ReLU()\n",
        "        in_features_pool = 20\n",
        "        out_features_pool = 18\n",
        "        kernel_pool = 3\n",
        "        padding_pool = int((out_features_pool - in_features_pool + kernel_pool - 1) / 2)\n",
        "        self.maxPool1d = nn.MaxPool1d(kernel_pool, padding=padding_pool, stride=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # #CONV2\n",
        "        kernel_size = 5\n",
        "        in_channels = 8\n",
        "        out_channels = 16\n",
        "        in_features = 18\n",
        "        out_features = 16\n",
        "        padding = int((out_features - in_features + kernel_size - 1) / 2)\n",
        "        self.cnn2 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        # #CONV3\n",
        "        kernel_size = 3\n",
        "        in_channels = 16\n",
        "        out_channels = 24\n",
        "        in_features = 16\n",
        "        out_features = 14\n",
        "        padding = int((out_features - in_features + kernel_size - 1) / 2)\n",
        "        self.cnn3 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        # #CONV4\n",
        "        kernel_size = 3\n",
        "        in_channels = 24\n",
        "        out_channels = 32\n",
        "        in_features = 14\n",
        "        out_features = 12\n",
        "        padding = int((out_features - in_features + kernel_size - 1) / 2)\n",
        "        self.cnn4 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        # LINEAR\n",
        "        self.mlp = nn.Linear(out_channels*out_features, self.params.OUTPUT_MLP_DIMENSION_FORECASTING)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.params.MULTIVARIATE:\n",
        "            x = torch.reshape(x, (-1, self.params.INPUT_FEATURE_DIMENSION, self.params.LAGS))\n",
        "        else:\n",
        "            x = torch.unsqueeze(x, dim=1)\n",
        "        h = self.maxPool1d(self.relu(self.cnn1(x)))\n",
        "        h = self.relu(self.cnn2(h))\n",
        "        h = self.relu(self.cnn3(h))\n",
        "        h = self.relu(self.cnn4(h))\n",
        "        h = h.reshape(h.size(0), -1)  # (1,1920)\n",
        "        h = self.mlp(h)\n",
        "        return h\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-0sMBFcxTGP"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qRrIGlnOxYDr"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import json\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class Dataset_custom(Dataset):\n",
        "\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "        self._read_json_data()\n",
        "        self.lags = None\n",
        "        self.features = None\n",
        "        self.features_corrupted = None\n",
        "        self.targets = None\n",
        "        self.features_temperatures = None\n",
        "        self.targets_temperatures = None\n",
        "        self.features_winds = None\n",
        "        self.targets_winds = None\n",
        "        self.number_of_station = None\n",
        "        self.encoded_data = []\n",
        "        self.read_dataset(self.params.LAGS)\n",
        "\n",
        "    def _read_json_data(self):\n",
        "        file = self.params.PATH_DATASET\n",
        "        with open(file) as f:\n",
        "            self._dataset = json.load(f)\n",
        "\n",
        "    def _get_edges(self):\n",
        "        self._edges = np.array(self._dataset[\"edges\"]).T\n",
        "\n",
        "    def _get_edge_weights(self):\n",
        "        self._edge_weights = np.array(self._dataset[\"weights\"]).T\n",
        "\n",
        "    def _get_targets_and_features(self):\n",
        "        # Power\n",
        "        stacked_target = np.stack(self._dataset[\"block\"])\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(stacked_target)\n",
        "        standardized_target = scaler.transform(stacked_target)\n",
        "        # Temperature\n",
        "        stacked_temp = np.stack(self._dataset[\"block_temp\"])\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(stacked_temp)\n",
        "        standardized_temp = scaler.transform(stacked_temp)\n",
        "        # Wind\n",
        "        stacked_wind = np.stack(self._dataset[\"block_wind\"])\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(stacked_wind)\n",
        "        standardized_wind = scaler.transform(stacked_wind)\n",
        "        # # Month\n",
        "        # stacked_month = np.stack(self._dataset[\"block_month\"])\n",
        "        # scaler = MinMaxScaler()\n",
        "        # scaler.fit(stacked_month)\n",
        "        # standardized_month = scaler.transform(stacked_month)\n",
        "        # # Hour\n",
        "        # stacked_hour = np.stack(self._dataset[\"block_hour\"])\n",
        "        # scaler = MinMaxScaler()\n",
        "        # scaler.fit(stacked_hour)\n",
        "        # standardized_hour = scaler.transform(stacked_hour)\n",
        "\n",
        "        self.number_of_station = stacked_target.shape[1]\n",
        "\n",
        "        self.features = [\n",
        "            # np.concatenate((standardized_target[i: i + self.lags, :].T,\n",
        "            #                 standardized_temp[i: i + self.lags, :].T,\n",
        "            #                 standardized_wind[i: i + self.lags, :].T,\n",
        "            #                 standardized_month[i: i + self.lags, :].T,\n",
        "            #                 standardized_hour[i: i + self.lags, :].T), axis=-1)\n",
        "            np.concatenate((standardized_target[i: i + self.lags, :].T,\n",
        "                            standardized_temp[i: i + self.lags, :].T,\n",
        "                            standardized_wind[i: i + self.lags, :].T), axis=-1)\n",
        "\n",
        "            # list of (4, 3, 24)\n",
        "            for i in range(standardized_target.shape[0] - self.lags - self.params.PREDICTION_WINDOW)\n",
        "        ]\n",
        "        self.features = self.features[:2300]\n",
        "\n",
        "        self.targets = [\n",
        "            # np.concatenate((standardized_target[i:i + self.params.PREDICTION_WINDOW, :].T,\n",
        "            #                 standardized_temp[i:i + self.params.PREDICTION_WINDOW, :].T,\n",
        "            #                 standardized_wind[i:i + self.params.PREDICTION_WINDOW, :].T,\n",
        "            #                 standardized_month[i:i + self.params.PREDICTION_WINDOW, :].T,\n",
        "            #                 standardized_hour[i:i + self.params.PREDICTION_WINDOW, :].T), axis=-1)\n",
        "            np.concatenate((standardized_target[i:i + self.params.PREDICTION_WINDOW, :].T,\n",
        "                            standardized_temp[i:i + self.params.PREDICTION_WINDOW, :].T,\n",
        "                            standardized_wind[i:i + self.params.PREDICTION_WINDOW, :].T), axis=-1)\n",
        "\n",
        "            for i in range(self.lags, standardized_target.shape[0] - self.params.PREDICTION_WINDOW)\n",
        "        ]\n",
        "        self.targets = self.targets[:2300]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_data[idx]\n",
        "\n",
        "    def read_dataset(self, lags) -> StaticGraphTemporalSignal:\n",
        "        self.lags = lags\n",
        "        self._get_edges()\n",
        "        self._get_edge_weights()\n",
        "        self._get_targets_and_features()\n",
        "        for i in range(len(self.features)):\n",
        "            self.encoded_data.append(Data(x=torch.FloatTensor(self.features[i]),\n",
        "                                          edge_index=torch.LongTensor(self._edges),\n",
        "                                          edge_attr=torch.FloatTensor(self._edge_weights),\n",
        "                                          y=torch.FloatTensor(self.targets[i])))\n",
        "\n",
        "\n",
        "class DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "        self.num_station = None\n",
        "        self.train_loader = None\n",
        "        self.val_loader = None\n",
        "        self.test_loader = None\n",
        "        dataset = Dataset_custom(self.params)\n",
        "        self.num_station = dataset.number_of_station  # len(loader.features[0])\n",
        "\n",
        "        len_dataset = len(dataset)\n",
        "        train_ratio = 0.7\n",
        "        val_test_ratio = 0.5\n",
        "        train_snapshots = int(train_ratio * len_dataset)\n",
        "        val_test_snapshots = len_dataset - train_snapshots\n",
        "        val_snapshots = int(val_test_ratio * val_test_snapshots)\n",
        "        test_snapshots = len_dataset - train_snapshots - val_snapshots\n",
        "        tr_db, val_db, te_db = torch.utils.data.random_split(dataset, [train_snapshots, val_snapshots, test_snapshots])\n",
        "        self.train_loader = DataLoader(tr_db, batch_size=self.params.BATCH_SIZE, shuffle=True)\n",
        "        self.val_loader = DataLoader(val_db, batch_size=self.params.BATCH_SIZE)\n",
        "        self.test_loader = DataLoader(te_db, batch_size=self.params.BATCH_SIZE)\n",
        "\n",
        "    # def setup(self, stage=None):\n",
        "\n",
        "    def get_len_loader(self):\n",
        "        len_train = 0\n",
        "        len_val = 0\n",
        "        len_test = 0\n",
        "        for _ in self.train_loader: len_train += 1\n",
        "        for _ in self.train_loader: len_val += 1\n",
        "        for _ in self.train_loader: len_test += 1\n",
        "        return len_train, len_val, len_test\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.val_loader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.test_loader\n",
        "\n",
        "\n",
        "class TrainingModule(pl.LightningModule):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "\n",
        "        # Index\n",
        "        self.index = 0\n",
        "        self.train_min_length = None\n",
        "        self.val_min_length = None\n",
        "        # Lr\n",
        "        self.learning_rate = self.params.LR\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "        if self.params.FORECASTING:\n",
        "            # Models\n",
        "            self.GNN_Forecasting = GNN_Forecasting(params)\n",
        "            #self.LSTM_Forecasting = LSTM_Forecasting(params)\n",
        "            #self.CNN_Forecasting = CNN_Forecasting(params)\n",
        "            self.mse_f = nn.MSELoss()\n",
        "\n",
        "    \"\"\" Index \"\"\"\n",
        "\n",
        "    def on_train_epoch_start(self):  # on_epoch_start\n",
        "        self.train_min_length = min(self.params.LIMIT_TRAIN_BATCHES, self.params.LEN_TRAIN)\n",
        "        self.val_min_length = min(self.params.LIMIT_VAL_BATCHES, self.params.LEN_VAL)\n",
        "        self.index = 1 #np.random.randint(0, self.val_min_length - 1)\n",
        "\n",
        "        # Updating LR\n",
        "        if self.current_epoch % self.params.LR_ITER == 0 and self.current_epoch > 0:\n",
        "            print('Updating learning rate at epoch: ', self.current_epoch)\n",
        "            main_opt = self.optimizers()\n",
        "            self.learning_rate = self.learning_rate * self.params.DECAY_LR\n",
        "            for group in main_opt.param_groups:\n",
        "                group[\"lr\"] = self.learning_rate\n",
        "        self.log('lr', self.learning_rate, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, edge_index, edge_weight):\n",
        "        output = self.GNN_Forecasting(input, edge_index, edge_weight)\n",
        "        #output = self.LSTM_Forecasting(input)\n",
        "        #output = self.CNN_Forecasting(input)\n",
        "        return output\n",
        "\n",
        "    \"\"\" Step \"\"\"\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        # Get data from batches\n",
        "        if self.params.MULTIVARIATE:\n",
        "            x = train_batch.x\n",
        "        else:\n",
        "            x = train_batch.x[:, :self.params.LAGS]\n",
        "        y = train_batch.y[:, :self.params.PREDICTION_WINDOW]\n",
        "        edge_index = train_batch.edge_index\n",
        "        edge_weight = train_batch.edge_attr\n",
        "\n",
        "        if self.params.FORECASTING:\n",
        "            main_opt = self.optimizers()\n",
        "            if self.params.MULTIVARIATE:\n",
        "                y_predicted= self.forward(x, edge_index, edge_weight)\n",
        "                #y_predicted = get_only_day_data(y, y_predicted, self.params.DEVICE)\n",
        "                loss_forecasting = self.mse_f(y_predicted, y)\n",
        "                loss_forecasting_tot = loss_forecasting\n",
        "                main_opt.zero_grad()\n",
        "                self.manual_backward(loss_forecasting_tot)\n",
        "                main_opt.step()\n",
        "                self.log('train_loss_FM_power', loss_forecasting, on_step=False, on_epoch=True, prog_bar=True,\n",
        "                         logger=True, batch_size=1)\n",
        "                train_mae = MAE(y_predicted.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
        "                self.log('train_MAE_FM', train_mae, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
        "                         batch_size=1)\n",
        "\n",
        "            else:\n",
        "                y_predicted = self.forward(x, edge_index, edge_weight)\n",
        "                #y_predicted = get_only_day_data(y, y_predicted, self.params.DEVICE)\n",
        "                loss_forecasting = self.mse_f(y_predicted, y)\n",
        "                main_opt.zero_grad()\n",
        "                self.manual_backward(loss_forecasting)\n",
        "                main_opt.step()\n",
        "                self.log('train_loss_FU', loss_forecasting, on_step=False, on_epoch=True, prog_bar=True,\n",
        "                         logger=True, batch_size=1)\n",
        "                train_mae = MAE(y_predicted.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
        "                self.log('train_MAE_FU', train_mae, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
        "                         batch_size=1)\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        # Get data from batches\n",
        "        if self.params.MULTIVARIATE:\n",
        "            x = val_batch.x\n",
        "        else:\n",
        "            x = val_batch.x[:, :self.params.LAGS]\n",
        "        y = val_batch.y[:, :self.params.PREDICTION_WINDOW]\n",
        "        x_power = x[:, :self.params.LAGS]\n",
        "        edge_index = val_batch.edge_index\n",
        "        edge_weight = val_batch.edge_attr\n",
        "\n",
        "        if self.params.FORECASTING:\n",
        "            if self.params.MULTIVARIATE:\n",
        "                y_predicted = self.forward(x, edge_index, edge_weight)\n",
        "                #y_predicted = get_only_day_data(y, y_predicted, self.params.DEVICE)\n",
        "                loss_forecasting = self.mse_f(y_predicted, y)\n",
        "                self.log('val_loss_FM_power', loss_forecasting, on_step=False, on_epoch=True, prog_bar=True,\n",
        "                         logger=True, batch_size=1)\n",
        "                val_mae = MAE(y_predicted.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
        "                self.log('val_MAE_FM', val_mae, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
        "                         batch_size=1)\n",
        "            else:\n",
        "                y_predicted = self.forward(x, edge_index, edge_weight)\n",
        "                #y_predicted = get_only_day_data(y, y_predicted, self.params.DEVICE)\n",
        "                loss_forecasting = self.mse_f(y_predicted, y)\n",
        "                self.log('val_loss_FU', loss_forecasting, on_step=False, on_epoch=True, prog_bar=True,\n",
        "                         logger=True, batch_size=1)\n",
        "                val_mae = MAE(y_predicted.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
        "                self.log('val_MAE_FU', val_mae, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
        "                         batch_size=1)\n",
        "            if (batch_idx == self.index) and self.params.LOGGER:\n",
        "                load_prediction_data_F2(x_power, y, y_predicted, self.params, \"Validation\")\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        # Get data from batches\n",
        "        if self.params.MULTIVARIATE:\n",
        "            x = test_batch.x\n",
        "        else:\n",
        "            x = test_batch.x[:, :self.params.LAGS]\n",
        "        y = test_batch.y[:, :self.params.PREDICTION_WINDOW]\n",
        "        x_power = x[:, :self.params.LAGS]\n",
        "        edge_index = test_batch.edge_index\n",
        "        edge_weight = test_batch.edge_attr\n",
        "\n",
        "        if self.params.FORECASTING:\n",
        "            if self.params.MULTIVARIATE:\n",
        "                y_predicted = self.forward(x, edge_index, edge_weight)\n",
        "                #y_predicted = get_only_day_data(y, y_predicted, self.params.DEVICE)\n",
        "                loss_forecasting = self.mse_f(y_predicted, y)\n",
        "                self.log('test_loss_FM_power', loss_forecasting, on_step=False, on_epoch=True, prog_bar=True,\n",
        "                         logger=True, batch_size=1)\n",
        "                test_mae = MAE(y_predicted.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
        "                self.log('test_MAE_FM', test_mae, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
        "                         batch_size=1)\n",
        "            else:\n",
        "                y_predicted = self.forward(x, edge_index, edge_weight)\n",
        "                #y_predicted = get_only_day_data(y, y_predicted, self.params.DEVICE)\n",
        "                loss_forecasting = self.mse_f(y_predicted, y)\n",
        "                self.log('test_loss_FU', loss_forecasting, on_step=False, on_epoch=True, prog_bar=True,\n",
        "                         logger=True, batch_size=1)\n",
        "                test_mae = MAE(y_predicted.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
        "                self.log('test_MAE_FU', test_mae, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
        "                         batch_size=1)\n",
        "            if (batch_idx == self.index) and self.params.LOGGER:\n",
        "                load_prediction_data_F2(x_power, y, y_predicted, self.params, \"Test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        main_opt = torch.optim.Adam(list(self.GNN_Forecasting.parameters()), lr=self.learning_rate)\n",
        "        return main_opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UaUkGZJxbDn"
      },
      "source": [
        "# **Main**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import wandb\n",
        "import numpy as np\n",
        "from time import strftime\n",
        "\n",
        "\n",
        "# System hyperparameters\n",
        "class HyperParameters():\n",
        "    NAME_PROJECT = 'Prova'\n",
        "    NAME_RUN = 'Run_' + strftime(\"%d/%m/%y\") + '_' + strftime(\"%H:%M:%S\")\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 4\n",
        "    EPOCHS = 100\n",
        "    LR = 1e-3\n",
        "    LR_ITER = 10\n",
        "    DECAY_LR = 0.9\n",
        "    LAGS = 24\n",
        "    PREDICTION_WINDOW = 24\n",
        "    NUM_STATION = 0\n",
        "    LEN_TRAIN = 0\n",
        "    LEN_VAL = 0\n",
        "    LEN_TEST = 0\n",
        "\n",
        "    # Model Parameters\n",
        "    GNN_MODEL = \"GConvLSTM\"\n",
        "    NODE_FEATURES = 24  # LAGS  # 32\n",
        "    FILTERS = 64  # 16\n",
        "    FILTER_SIZE = 2\n",
        "    DROPOUT = 0.1\n",
        "\n",
        "    # MLP Parameters\n",
        "    INPUT_MLP_DIMENSION = FILTERS\n",
        "    OUTPUT_MLP_DIMENSION_IMPUTATION = PREDICTION_WINDOW\n",
        "    OUTPUT_MLP_DIMENSION_FORECASTING = PREDICTION_WINDOW\n",
        "    INPUT_FEATURE_DIMENSION = 1\n",
        "\n",
        "    #LSTM Parameters\n",
        "    HIDDEN_DIMENSION_SINGLE = 30\n",
        "    NUMBER_LSTM_LAYERS = 2\n",
        "\n",
        "\n",
        "    # Use case\n",
        "    FORECASTING = False\n",
        "    MULTIVARIATE = False\n",
        "\n",
        "    # Training\n",
        "    SAVE_IMGS = True\n",
        "    DEBUG = False\n",
        "    REPRODUCIBLE = False\n",
        "    SEED = 42\n",
        "    NUM_GPUS = 0\n",
        "    if NUM_GPUS == 1:\n",
        "        DEVICE = \"cuda\"\n",
        "    else:\n",
        "        DEVICE = \"cpu\"\n",
        "    NUM_WORKERS = 2  # multiprocessing.cpu_count()\n",
        "    FAST_DEV_RUN = False\n",
        "    LOGGER = True\n",
        "    BAR_REFRESH_RATE = 1\n",
        "    GRADIENT_CLIP = 0\n",
        "    ACCUMULATE_GRADIENT_BATCHES = 1\n",
        "    LIMIT_TRAIN_BATCHES = 1.0  # 1.0 # 1500\n",
        "    LIMIT_VAL_BATCHES = 1.0  # 1.0 # 400\n",
        "    LIMIT_TEST_BATCHES = 1.0\n",
        "    AUTO_LR_FIND = False\n",
        "    CHECK_VAL_EVERY_N_EPOCH = 4\n",
        "\n",
        "    # Dataset\n",
        "    DATA_MAP1 = {'PV4': 'H:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_with_weigth_light_multivariate'\n",
        "                       '.json',\n",
        "                'PV31': 'H:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_with_weigth_multivariate_T50'\n",
        "                        '.json',\n",
        "                'PV31T': 'H:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_31_with_weigth_multivariate_and_time'# \n",
        "                         '.json',\n",
        "                'PV10': 'H:\\Il mio Drive\\PhD ICT\\Data\\Real_time_series_output_3Months_with_weigth_multivariate_T150.json'}\n",
        "\n",
        "    # Dataset\n",
        "    DATA_MAP2 = {'PV4': 'G:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_with_weigth_light_multivariate'\n",
        "                       '.json',\n",
        "                'PV31': 'G:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_with_weigth_multivariate_T50'\n",
        "                        '.json',\n",
        "                'PV31T': 'G:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_31_with_weigth_multivariate_and_time'    \n",
        "                         '.json',\n",
        "                'PV10': 'G:\\Il mio Drive\\PhD ICT\\Data\\Real_time_series_output_3Months_with_weigth_multivariate_T150.json'}\n",
        "\n",
        "    # Path\n",
        "    PATH_DATASET = DATA_MAP2['PV4']\n",
        "\n",
        "    # Other\n",
        "    NOTES = \"\"\n",
        "\n",
        "\n",
        "params = HyperParameters()\n",
        "results = []\n",
        "\n",
        "###################  EXPERIMENT SETUP #################################################################################\n",
        "params.DEBUG = False\n",
        "params.NAME_PROJECT = 'TEST_NOTTE'\n",
        "params.EPOCHS = 100\n",
        "params.GNN_MODEL = \"GNN\"\n",
        "\n",
        "# Window\n",
        "in_ws = 24\n",
        "params.LAGS = in_ws\n",
        "out_win = 24\n",
        "params.PREDICTION_WINDOW = out_win\n",
        "params.OUTPUT_MLP_DIMENSION_FORECASTING = out_win\n",
        "\n",
        "# Task\n",
        "params.FORECASTING = True\n",
        "params.MULTIVARIATE = False\n",
        "if params.MULTIVARIATE:\n",
        "    params.INPUT_FEATURE_DIMENSION = 3\n",
        "\n",
        "# Dataset\n",
        "db = 'PV4'\n",
        "#params.PATH_DATASET = params.DATA_MAP1[db]\n",
        "#params.PATH_DATASET = 'H:\\Il mio Drive\\PhD ICT\\Data\\Generated_time_series_output_29_with_weigth_multivariate_and_time.json'\n",
        "params.PATH_DATASET = '/content/drive/My Drive/PhD ICT/Data/Generated_time_series_output_with_weigth_light_multivariate.json'\n",
        "\n",
        "\n",
        "# Runs\n",
        "RUNS = 3\n",
        "params.REPRODUCIBLE = False\n",
        "params.EXP_NAME = get_run_name(db, in_ws, out_win, params)\n",
        "params.LOGGER = False\n",
        "#######################################################################################################################\n",
        "\n",
        "if params.DEBUG:\n",
        "    params.EPOCHS = 2\n",
        "    params.LIMIT_TRAIN_BATCHES = 100\n",
        "    params.LIMIT_VAL_BATCHES = 100\n",
        "    params.LIMIT_TEST_BATCHES = 100\n",
        "    params.LOGGER = False\n",
        "\n",
        "for i in range(RUNS):\n",
        "    if params.REPRODUCIBLE:\n",
        "        torch.manual_seed(params.SEED)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        random.seed(params.SEED)\n",
        "        np.random.seed(params.SEED)\n",
        "    start = time.time()\n",
        "    data_module = DataModule(params)\n",
        "    params.NUM_STATION = data_module.num_station\n",
        "    params.LEN_TRAIN, params.LEN_VAL, params.LEN_TEST = data_module.get_len_loader()\n",
        "    print('Number of station: ', str(params.NUM_STATION))\n",
        "    params.NAME_RUN = params.EXP_NAME + '__' + strftime(\"%d/%m/%y\") + '_' + strftime(\"%H:%M:%S\")\n",
        "    print(\"Run name: \", params.NAME_RUN)\n",
        "    model = TrainingModule(params)\n",
        "    params_dict = get_hyperparams_dict(params)\n",
        "    checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\", save_top_k=2, monitor=\"val_loss_FM_power\")\n",
        "\n",
        "    # Logger\n",
        "    if params.LOGGER:\n",
        "        wandb.login()\n",
        "        wandb.init(project=params.NAME_PROJECT, name=params.NAME_RUN, entity=\"alessio_v\", config=params_dict)\n",
        "        params.LOGGER = WandbLogger(log_model=False)\n",
        "        # wandb_logger.watch(model, log_freq=100)  # log='gradients',\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=params.EPOCHS,\n",
        "        fast_dev_run=params.FAST_DEV_RUN,\n",
        "        logger=params.LOGGER,\n",
        "        progress_bar_refresh_rate=params.BAR_REFRESH_RATE,\n",
        "        gpus=params.NUM_GPUS,\n",
        "        gradient_clip_val=params.GRADIENT_CLIP,\n",
        "        check_val_every_n_epoch=params.CHECK_VAL_EVERY_N_EPOCH,\n",
        "        accumulate_grad_batches=params.ACCUMULATE_GRADIENT_BATCHES,\n",
        "        limit_train_batches=params.LIMIT_TRAIN_BATCHES,\n",
        "        limit_val_batches=params.LIMIT_VAL_BATCHES,\n",
        "        limit_test_batches=params.LIMIT_TEST_BATCHES,\n",
        "        auto_lr_find=params.AUTO_LR_FIND)#, callbacks=[checkpoint_callback]\n",
        "        # precision=32\n",
        "        # deterministic=True\n",
        "    #)\n",
        "\n",
        "    # LOAD_PATH = r'H:\\Il mio Drive\\PhD ICT\\Code\\Fase_2\\Projects\\test_architettura_2\\test_6\\checkpoints\\epoch=51-step=83719.ckpt'  #BS=64, FS=2, EP=4\n",
        "    # model = TrainingModule.load_from_checkpoint(LOAD_PATH, params=params)\n",
        "    # trainer.test(model, data_module)\n",
        "    # trainer.tune(model, data_module)\n",
        "    trainer.fit(model, data_module)\n",
        "    loss_dict = trainer.test(model, data_module)\n",
        "    results.append(loss_dict[0])\n",
        "    if params.LOGGER: wandb.finish()\n",
        "    end = time.time()\n",
        "    total_time = (end - start)/60\n",
        "    print('Total time of training: ', str(total_time))\n",
        "\n",
        "print_runs_results(params, RUNS, results)\n"
      ],
      "metadata": {
        "id": "clRPwR8Yoirq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "c2b02cad384c4f78b09024ed99bf00bc",
            "a65a3b753c034a40bb470262ae67da39",
            "abc37fb8b7fe456e8f2ea7c752d817c7",
            "df8e7790e0a847abb0079dcf97c97efd",
            "9a3ead8042394a378ed87dd096af6c91",
            "1e096967a54c4039b8376f0a77935a52",
            "bf0dfb19bd824bfc93ba8f6bbea60d83",
            "9be2012b44994772abc65c916d020b6c",
            "24d7ecbfa1bf4f8d98d3db2ba65125dc",
            "623843d4423a4c6b9be6b63a8b79a716",
            "f253c4daff2c471da67c484a347ccd39",
            "f03b6eb240ae4de9820299af4a0560ef",
            "85b0091ea7114bffaad09982571b5fd3",
            "a834ce75e8da439baa36f63ec3484563",
            "45707f55d48d437dabe62a6fa4c3d940",
            "ff5d3aef77394947ab76f787139dc0fb",
            "8a57497410f64eb5b0ca1cb8df15022b",
            "26e0bbb7e9104856ac0c3bfa3498ecd1",
            "6f33bea12e87434e84c8e91f43ce9ea1",
            "147199fa51304f57800f0b39e00ba8e0",
            "eb88804308074484aeb5fbc2508760fc",
            "13bf2f77781a49e38f540a9e97cb5f0f"
          ]
        },
        "outputId": "4b6867aa-0f26-44d5-9014-256c145be837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "\n",
            "  | Name            | Type            | Params\n",
            "----------------------------------------------------\n",
            "0 | GNN_Forecasting | GNN_Forecasting | 102 K \n",
            "1 | mse_f           | MSELoss         | 0     \n",
            "----------------------------------------------------\n",
            "102 K     Trainable params\n",
            "0         Non-trainable params\n",
            "102 K     Total params\n",
            "0.409     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of station:  4\n",
            "Run name:  GNN_F_PV4_24_24__29/04/22_23:45:52\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2b02cad384c4f78b09024ed99bf00bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f03b6eb240ae4de9820299af4a0560ef"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GNN_corretta_colab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2b02cad384c4f78b09024ed99bf00bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a65a3b753c034a40bb470262ae67da39",
              "IPY_MODEL_abc37fb8b7fe456e8f2ea7c752d817c7",
              "IPY_MODEL_df8e7790e0a847abb0079dcf97c97efd"
            ],
            "layout": "IPY_MODEL_9a3ead8042394a378ed87dd096af6c91"
          }
        },
        "a65a3b753c034a40bb470262ae67da39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e096967a54c4039b8376f0a77935a52",
            "placeholder": "",
            "style": "IPY_MODEL_bf0dfb19bd824bfc93ba8f6bbea60d83",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "abc37fb8b7fe456e8f2ea7c752d817c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be2012b44994772abc65c916d020b6c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24d7ecbfa1bf4f8d98d3db2ba65125dc",
            "value": 1
          }
        },
        "df8e7790e0a847abb0079dcf97c97efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623843d4423a4c6b9be6b63a8b79a716",
            "placeholder": "",
            "style": "IPY_MODEL_f253c4daff2c471da67c484a347ccd39",
            "value": " 2/2 [00:00&lt;00:00,  3.02it/s]"
          }
        },
        "9a3ead8042394a378ed87dd096af6c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1e096967a54c4039b8376f0a77935a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0dfb19bd824bfc93ba8f6bbea60d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9be2012b44994772abc65c916d020b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d7ecbfa1bf4f8d98d3db2ba65125dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "623843d4423a4c6b9be6b63a8b79a716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f253c4daff2c471da67c484a347ccd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f03b6eb240ae4de9820299af4a0560ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85b0091ea7114bffaad09982571b5fd3",
              "IPY_MODEL_a834ce75e8da439baa36f63ec3484563",
              "IPY_MODEL_45707f55d48d437dabe62a6fa4c3d940"
            ],
            "layout": "IPY_MODEL_ff5d3aef77394947ab76f787139dc0fb"
          }
        },
        "85b0091ea7114bffaad09982571b5fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a57497410f64eb5b0ca1cb8df15022b",
            "placeholder": "",
            "style": "IPY_MODEL_26e0bbb7e9104856ac0c3bfa3498ecd1",
            "value": "Epoch 2:  35%"
          }
        },
        "a834ce75e8da439baa36f63ec3484563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f33bea12e87434e84c8e91f43ce9ea1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_147199fa51304f57800f0b39e00ba8e0",
            "value": 1
          }
        },
        "45707f55d48d437dabe62a6fa4c3d940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb88804308074484aeb5fbc2508760fc",
            "placeholder": "",
            "style": "IPY_MODEL_13bf2f77781a49e38f540a9e97cb5f0f",
            "value": " 140/403 [04:43&lt;08:53,  2.03s/it, lr=0.001, train_loss_FU=0.0245, train_MAE_FU=0.092]"
          }
        },
        "ff5d3aef77394947ab76f787139dc0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8a57497410f64eb5b0ca1cb8df15022b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e0bbb7e9104856ac0c3bfa3498ecd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f33bea12e87434e84c8e91f43ce9ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147199fa51304f57800f0b39e00ba8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb88804308074484aeb5fbc2508760fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13bf2f77781a49e38f540a9e97cb5f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}